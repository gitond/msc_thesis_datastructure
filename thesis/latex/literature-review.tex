\chapter{Literature review} \label{Literature review}

\section{Computer Vision (CV)} \label{cv}
% This should include the Client-Server Architecture stuff


\section{Prototypes Similar to Ours} \label{protos}
Before designing and describing our own software architecture it is 
worthwhile to look at applications other people have developed that solve a 
problem similar to ours. A great example of such an application is the work 
done by \textcite{pylvanainen}. \par
	The work conducted by \textcite{pylvanainen} started from a simple
observation: They coulnd't find any mobile apps for microscopy education that 
incorporated AR and Virtual Reality (VR) features and step-by-step guidance. 
They then sent out a needs assesment survey to students to map out demand for 
such a software and found that 70\% of the respondents showed interest in 
using such an app in their microscopy studies.\cite{pylvanainen} They then 
outlined goals for such an app and started to develop it. 
\textcite{pylvanainen} state that their application should:
\begin{enumerate}
	\item Be a useful tool in teaching microscopy
	\item Help its users to operate a microscope
	\item Be a helpful tool with troubleshooting microscopy related issues
	\item Be a tool that could be used to revive microscopy knowledge after a long pause in practicing microscopy skills
\end{enumerate} \par
	The app developed by \textcite{pylvanainen} consists of three 
sections: "Teach me microscopy", "Help me at the microscope" and "Help me to 
troubleshoot". What's relevant to this thesis is under "Help me at the 
microscope". In that section there is the option to view a 3D-model of a 
specific microscope commonly used in laboratories (Leica DM RXA microscope). 
Interactive step-by-step tutorials are also available for this microscope on 
various things, such as microscopy parts, setting optimal Köhler alignment 
and focusing the microscope on the sample. These tutorials are also usable 
outside the virtual microscope in the real world as the "Help me at the 
microscope"-section also acts as a marker-based 
AR-environment.\cite{pylvanainen} AR-markers put on the microscopes can also 
help students find different parts of the microscope and learn of their 
functions. This system can also be used to integrate microscope-specific 
information into this AR-environment.\cite{pylvanainen} \par
	\textcite{pylvanainen} also conducted a questionnaire-based usability 
study on the app they developed, and found that using the app during 
microscopy education increased the students' confidence at later using the 
same microscope independently, without assistance. Furthermore 64\% of the 
students reported that the app definitely helped them at learning microscopy 
and 90\% of them reported that the app helped them recall microscopy skills 
later.\cite{pylvanainen} \par
	Another quite similar project is the work carried out by 
\textcite{estrada}. Their work was built on a simple goal: To enable students 
to have a better experience when learning how to use electrical engineering 
laboratory equipment. They aimed to do this by offering the students AR-based 
tutorials for various electrical engineering lab equipment, and by using Deep 
Learning (DL) methods to detect such equipment in the 
laboratory.\cite{estrada} The long term goal of this project was to create a 
framework that could be later used to easily develop interactive smartphone 
apps for different laboratory devices integrating this 
concept.\cite{estrada} \par
	Essentially \textcite{estrada} developed a superimposition-based 
AR-app with an integrated DL-model to be used for object detection. This 
application can be used for a template to create any AR-based tutorial for 
any device. Creating a tutorial for a device using this framework consists of 
three steps of work:
\begin{enumerate}
	\item Training the DL-model to recognize the device
	\item Creating an Augmented Reality User Interface (AR-UI) of the device, consisting of a 3D-model and User Interface (UI) panels
	\item Creating step-by-step instructions that can be displayed using the AR-UI defined in the first step.
\end{enumerate} \par
	On top of designing and defining such a framework, \textcite{estrada} 
actually developed an application using it. In this application the DL-model 
was trained to detect various types of multimeters, oscilloscopes, wave 
generators and power supplies. They also created AR-UIs and step-by-step 
tutorials for using real multimeters.\cite{estrada}\par
	The application logic of the app by \textcite{estrada} is as follows: 
First the DL-model detects (so classifies and localizes) the equipment. Next 
if a tutorial is available for that equipment, the UI notifies the user of this.
If the user decides to view the tutorial, the AR-based tutorial gets loaded 
and the AR-UI gets superimposed on top of the real object. Then UI-panels are 
used to display the tutorial content. \par
\\
\\
\\
Stepping outside of the laboratory setting, \textcite{VanGestel2024} developed 
an AR-application for helping orthopedic procedures. Namely they wanted to 
create a tool that would act as a new real-time AR-based safety solution and 
guidance technique in the use of power tools in surgery. Prior to this there 
did exist other camera and AR-based surgery systems but 
\textcite{VanGestel2024} noted them to be physically too large, expensive and 
time-consuming, which was said to limit their usefulness in assisting with 
performing surgeries. \textcite{VanGestel2024} wanted to develop a solution 
that could run on a head-mounted display (HMD) so that a surgeon could use 
it while working with his/her hands. However one problem was that HMDs 
typically couldn't do accurate enough tracking for surgical 
use.\cite{VanGestel2024}\par
	\textcite{VanGestel2024} don't describe the structure and logic 
of the software built for their task very deeply. They do mention building it 
for Microsoft's HoloLens headset, and circumventing the poor performance of 
its camera's tracking ability by using the built in infrared sensor 
instead.\cite{VanGestel2024} They measured the infrared sensor's tracking 
accuracy to be below 1mm, accurate enough for surgical 
work.\cite{VanGestel2024} Their software technically uses marker-based AR, 
however it must be noted that the markers they use are not physical markers, 
rather markers registered by an infrared-tracked stylus at the key positions 
to the surgical operation.\cite{VanGestel2024} These virtual markers were then 
used to show the users an AR-based guidance vector representing the desired 
drilling direction when performing the surgery. The vector would also change 
color to represent whether the current drilling direction was correct or not. 
If the surgeon was drilling in the right direction the vector would be green, 
otherwise the vector would be orange or red.\cite{VanGestel2024}\par
	This software was then tested by letting 18 people perform mock 
surgeries on wooden models.\cite{VanGestel2024} Three surgery guidance 
techniques were compared: freehand surgery without guidance, 
proprioception-guided surgery and surgery using the new 
AR-tool.\cite{VanGestel2024} The mock surgeries were quite simple: the wooden 
bone-models had defined entry and exit points between which the surgeons had 
to drill, with parts of the models being covered by a cloth to better 
simulate real conditions.\cite{VanGestel2024} The success of mock surgeries 
was examined by measuring the distances and angles between the desired exit 
point and the actual exit points drilled by the surgeons.\cite{VanGestel2024} 
They also performed statistical analysis on the drilling session results, 
considering the angle between the actual and planned exit points a variable 
dependent on the experience level of the surgeon, the guidance technique used 
and the desired drilling direction.\cite{VanGestel2024} They found that the 
AR guidance tool they developed improved the surgeons' output regardless of 
experience level.\cite{VanGestel2024} The AR tool was an especially useful 
tool when performing oblique, complex and angled drilling paths. With these 
drilling paths the difference between AR-guidance and traditional guidance was 
even more pronounced.\cite{VanGestel2024}\par
	Another prototype was developed by \textcite{reyesEtAl2016}. Their aim 
was to develop an AR system to aid novice users in using milling and lathe 
machines in a school manufacturing laboratory, and use this as a basis to 
measure the acceptance rate and performance of such a system in the field of 
education.\cite{reyesEtAl2016} Since they designed a tool to aid with the 
physical operation of industrial machinery, it was important to them that their 
tool was hands-free as the users would need to operate the industrial 
machinery simultaneously.\cite{reyesEtAl2016}\par
	\textcite{reyesEtAl2016} emphasized that their system was a Mobile 
Augmented Reality (MAR) system, so essentially it was technically an 
application built for the Android Operating System. Contentwise their 
application included tutorials for a milling and a lathe machine which would 
guide the users in tool setup, working material setup, machinery setup and 
starting the machines in question.\cite{reyesEtAl2016} The AR-elements in this 
app included 3D-models of the machines themselves as well as additional 
tools, such as spanners and Allen wrenches, as well as text instructions with 
descriptions on how to perform the basic tasks, labels for helping the user 
in locating machinery components and tools, 3D arrows to indicate flow 
direction, and real time videos of task explanations performed by 
experts.\cite{reyesEtAl2016}\par
	Since the two-hand requirement made it undesirable to run the 
application on a smartphone, two AR-devices were chosen to run the 
application in the experimental phase. Firstly ORA-1 AR glasses, which are 
optical see-through glasses where the real world is observed through 
transparent mirrors placed in front of the eyes of the user, and the VR-PRO 
AR HMD, which is just a HMD with video see-through.\cite{reyesEtAl2016} Their 
AR solution was simply Marker-based MAR with two kinds of markers: Frame 
markers (FM), which are traditional AR-markers, so frame patterns with encoded 
data in the frame, and Item Targets (IT) which are real world objects that 
the system tries to match to a 2D image using traditional CV-algorithms such 
as edge detection and corner detection.\cite{reyesEtAl2016} The purpose of the 
markers in this system is to help the system detect the machinery, and 
provide the system with placement information for the augmentations and 
explanation videos.\cite{reyesEtAl2016}\par
	\textcite{reyesEtAl2016} describe the flow of the application as 
follows: first the user needs to start the system by scanning the main menu 
marker. Then they will enter the main menu. From here the user can either 
start the application or get system help information. The system help 
information gives the users info on how to use the app. Once the application 
is started, the user can scan the device markers, which then lets the user 
scan the individual lesson markers and multimedia markers for that device. 
This lets the user access the interactive tutorials and educational videos 
which actually help him/her to learn the operation of that 
machine.\cite{reyesEtAl2016}\par
	This application was then tested by 16 students and teachers in the 
university manufacturing laboratory for an experiment.\cite{reyesEtAl2016} In 
the experiment the subjects were first given a general introduction to AR, 
after which they were introduced to the AR-system developed for this study. 
Then they were asked to complete the lessons included in the AR-systems on 
one of the two hardware options that was available. Finally the participants 
were asked to complete a survey to gather results.\cite{reyesEtAl2016} The 
survey was a 10-question survey with a Likert-scale scoring-system. The first 
five questions related to acceptance metrics (satisfaction, precision, 
understandability, explanativeness, attractiveness). The next three questions 
related to performance metrics (interface, speed, marker system). This was 
followed by a generic "Have you used mobile AR systems before?"-type of 
question. The last question was an oper answer field where they asked for 
feedback and comments.\cite{reyesEtAl2016}\par
	For each question they calculated a score by doing a Likert-scale to 
point conversion where "very bad" became 1, "regular" became 3, and "very 
good" became 5, and then calculating the average from all the answers. The 
scores for the different metrics were: satisfaction: 4; precision: 4; 
understandability: 4,5; explanativeness: 4; attractiveness: 4,5; interface: 
3,5; speed: 4 and marker system: 4,5. Out of these interface was the weakest 
element, with only 50\% of the respondents rating it as good or very 
good.\cite{reyesEtAl2016} According to the feedback from the open answer 
field the teachers and the lab staff participating in this study were 
interested in using the AR-system developed for this experiment as an 
educational tool later. The students also saw it as an appealing way to learn 
machine operation basics.\cite{reyesEtAl2016} With this it is pretty clear to 
say that the system developed for this project has potential to be a 
real-life teaching-learning tool.\par
	A somewhat similar tool was also developed by 
\textcite{LinAndLee2020}. With it they aim to use AR-simulation as a 
practical aid to deepen students' understanding of CNC machine operation. 
This should help the students to learn operate CNC machines independently 
while also helping to solve resource limitation problems in education. 
Oftentimes workshops in vocational education only have a limited number of 
CNC machines when compared to the demand, as well as insufficient space for 
operation. On top of there are also a limited amount of processing materials 
and the wearing of the machines themselves during operation is also a real 
issue.\cite{LinAndLee2020} All these problems lead to an outcome where 
students don't get enough practice on CNC machining.\cite{LinAndLee2020}\par
	There are also issues with traditional education methods that make 
learning proper CNC machine operations difficult. For example it is hard for 
students to understand, how the physical size and movement capabilities of 
CNC machines relate to the workpiece models they create using modeling 
software.\cite{LinAndLee2020} Different three dimensional and complicated 
manufacturing processes and methods, such as turning over processing and mold 
hole processing among others, are extremely difficult to properly showcase 
without using three dimensional visualization.\cite{LinAndLee2020} 
Furthermore it is difficult for students to understand how the instructions 
sent to the CNC machine actually affect the workpiece itself during 
manufacturing.\cite{LinAndLee2020}\par
	To solve these problems \textcite{LinAndLee2020} proposed using AR to 
simulate CNC machine operation and the machining process.\cite{LinAndLee2020} 
They built an AR application where the built-in virtual imaging technology 
can superimpose virtual 3D machining workpieces on the physical CNC machine 
using mobile hardware, such as tablets, as displays.\cite{LinAndLee2020} 
While \textcite{LinAndLee2020} do not discuss the workings or contents of 
their application in-depth, they still disclose that they used AR-markers 
corresponding to different operation processes. They placed these markers on 
the CNC machine itself so that their system could be used in the real 
manufacturing workshop setting.\cite{LinAndLee2020} \textcite{LinAndLee2020} 
also disclose that their application includes pre-made animations for 
different manufacturing processes supported by the CNC machine.\par
	\textcite{LinAndLee2020} used their application to conduct a ten 
participant study consisting of tool-aided CNC machine operation, followed by 
filling out System Usability Scale-type questionnaire (SUS). The participants 
had prior CNC machine experience, but were still novice level 
students.\cite{LinAndLee2020} These students used the app to simulate 
operating a CNC machine to manufacture an example furniture piece. The SUS 
consisted of 20 questions in total each scored 1-7, where 1 is high 
difficulty and 7 is low difficulty. The questions were of five different 
evaluation dimensions: “Understanding of Machining Procedures”, “Time of 
Operation”, “Accuracy of Operation”, “Sequence and Information of the CNC 
Operation Steps” and “Understanding of the Interface Knowledge of the CNC 
Cutting Machine Center”.\cite{LinAndLee2020} Each of these categories acquired 
a score of 4,86; 4,8; 5,52; 4,98 and 5,6 respectively.\cite{LinAndLee2020}\par
	The results of the experiment showed that the AR system helped the 
students to understand the relationship between the workpieces and the CNC 
machining methods.\cite{LinAndLee2020} \textcite{LinAndLee2020} also listed 
the following advantages they found in using AR-based system for learning CNC 
machine operations:
\begin{enumerate}
	\item Students understood and were able to complete necessary steps of using CNC machine for making furniture.
	\item Students understood the relationship between the virtual representations of processing objects and the real-world procedure.
	\item The system reduced the work needed to be done by the teachers in teaching operating the CNC machine to students.
	\item Students were able to practice CNC machine operation more as they weren't limited by machine availability anymore. This also decreased material waste and safety risks.
	\item Students were able to preview the interaction between models done by them and the cutting path of the CNC machine.
\end{enumerate}
